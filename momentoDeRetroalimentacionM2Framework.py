# -*- coding: utf-8 -*-
"""momentoDeRetroalimentacionM2Framework.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/150o-AdL_oTvRMdK0-pg-mBZLMBTuwMG9

#  Implementación de una técnica de ML (Framework)
"""

'''
Momento de Retroalimentación: Módulo 2 Uso de framework o biblioteca de 
aprendizaje máquina para la implementación de una solución. 
(Portafolio Implementación)

Jorge Chávez Badillo A01749448

09-09-2022
'''

# Importación de Librerías 
import graphviz
import numpy as np 
import pandas as pd
import seaborn as sns
from sklearn import tree
from sklearn import metrics
import matplotlib.pyplot as plt
from sklearn.tree import DecisionTreeClassifier
from sklearn.preprocessing import StandardScaler
from mlxtend.plotting import plot_learning_curves
from sklearn.model_selection import train_test_split

"""## Lectura de Datos"""

# Dataset Breast Cancer
df = pd.read_csv('/content/breast_cancer.csv')
df.drop(columns = ['Unnamed: 0'], inplace=True)
df

"""## Entendimiento de Datos

### Verificación de los Tipos de Datos
"""

'''
Observar los tipos de datos del dataset
'''

df.info()

"""### Búsqueda de Valores Nulos"""

'''
Se genera una tabla donde se obtiene el porcentage de valores nulos en 
el dataset para poder decidir si se hace o no una limpieza de datos para 
procesar los datos que estén incompletos.
'''

total = df.isnull().sum().sort_values(ascending=False)
percent_1 = df.isnull().sum() / df.isnull().count()*100
percent_2 = (round(percent_1, 1)).sort_values(ascending=False)
missing_data = pd.concat([total, percent_2], axis=1, keys=['Total', '%'])
missing_data.head()

"""### Análisis Estadístico """

'''
Se obtienen estadísticos generales sobre el dataset para poder 
observar el comportamiento
'''

df.describe()

# Comparación de Valores Benignos (1) y Malignos (0)
sns.countplot(df['status'], label="Count", palette = 'Set2').set(title = 'Valores Benignos (1) vs Malignos (0)')
plt.show()

sns.relplot(data = df, x = 'mean radius', y = 'mean concavity', hue = 'status').set(title = 'Radio vs Concavidad')

sns.relplot(data = df, x = 'mean perimeter', y = 'mean area', hue = 'status').set(title = 'Perímetro vs Área')

"""### Búsqueda de Correlaciones"""

# Matriz de Correlación
correlationMatrix = df.corr()
correlationMatrix.style.background_gradient(cmap='GnBu')

"""## Limpieza y Preparación de los Datos

### Separación del Dataset en Training y Test
"""

'''Ya que no existen valores nulos, solo es necesario preparar los datos para 
ser procesados por el modelo, separar en valores de entrenamiento y pruebas, 
además del escalamiento de los valores de x'''

x = df.copy().drop(columns = ['status'])
y = df['status']

# Training y Testing
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.20, random_state = 0)

"""### Escalamiento Datos de X"""

# Escalamiento de x
escalador = StandardScaler()
x_train = escalador.fit_transform(x_train)
x_test = escalador.transform(x_test)

"""## Modelo Elegido

### Árboles de Decisión (Decision Tree)

### Pruebas con Diferentes Parámetros
"""

# Configuración del Modelo de Árbol de Decisión

# Árbol 1
decisionTree1 = DecisionTreeClassifier(random_state = 0, 
                                       max_depth = 3)
decisionTree1.fit(x_train, y_train)
print('=' * 10, 'Árbol 1', '=' * 10)
print('Score: ', decisionTree1.score(x_train, y_train))
print()

# Árbol 2
decisionTree2 = DecisionTreeClassifier(criterion = 'entropy', 
                                       random_state = 0, 
                                       max_depth = 6)
decisionTree2.fit(x_train, y_train)
print('=' * 10, 'Árbol 2', '=' * 10)
print('Score: ', decisionTree2.score(x_train, y_train))
print()

# Árbol 3
decisionTree3 = DecisionTreeClassifier(criterion = 'entropy', 
                                       random_state = 0, 
                                       max_depth = 6, 
                                       min_samples_split = 4,
                                       min_impurity_decrease=0.01)
decisionTree3.fit(x_train, y_train)
print('=' * 10, 'Árbol 3', '=' * 10)
print('Score: ', decisionTree3.score(x_train, y_train))
print()

# Árbol 4
decisionTree4 = DecisionTreeClassifier(criterion = 'entropy', 
                                       random_state = 0, 
                                       max_depth = 4,
                                       min_impurity_decrease=0.01)
decisionTree4.fit(x_train, y_train)
print('=' * 10, 'Árbol 4', '=' * 10)
print('Score: ', decisionTree4.score(x_train, y_train))
print()

# Árbol 5
decisionTree5 = DecisionTreeClassifier(criterion = 'entropy', 
                                       random_state = 0, 
                                       max_depth = 6,
                                       min_samples_leaf=8,
                                       min_impurity_decrease=0.02)
decisionTree5.fit(x_train, y_train)
print('=' * 10, 'Árbol 5', '=' * 10)
print('Score: ', decisionTree5.score(x_train, y_train))
print()

'''
De acuerdo a los scores obtenidos, tenemos que los parámetros utilizados en
en el árbol número dos tienen un valor más alto, por ello, procedemos a obtener
el mejor valor de alpha para posteriormente hacer las predicciones. 
'''

decisionTree2.get_params()

"""### Búsqueda del Mejor Valor de Alpha"""

# Obtención de los valores de alpha para encontrar el que tenga mejor desempeño
pruning_data = decisionTree2.cost_complexity_pruning_path(x_train, y_train)
alphaValues = pruning_data.ccp_alphas
impurityValues = pruning_data.impurities
print('Alpha Values: ', alphaValues)

'''
Creación de árboles con los valores de alpha para decidir 
el que tenga un mejor desempeño.
'''

allTrees = []

for thisAlpha in alphaValues:
  thisTree=tree.DecisionTreeClassifier(criterion = 'entropy', 
                                       random_state = 0, 
                                       max_depth = 6, 
                                       ccp_alpha = thisAlpha)
  thisTree.fit(x_train, y_train)
  allTrees.append(thisTree)

# Comparación de desempeño para cada árbol 
allTrainScores = []
allTestScores = []

for thisTree in allTrees:
  allTrainScores.append(thisTree.score(x_train, y_train))
  allTestScores.append(thisTree.score(x_test, y_test))

print('Alpha Values: ', alphaValues)
print('Trainning Scores: ', allTrainScores)
print('Testing Scores: ', allTestScores)

plt.figure(figsize = (10, 6))
plt.grid()
plt.plot(alphaValues, allTrainScores, linestyle = 'dotted', marker = 'o')
plt.plot(alphaValues, allTestScores, linestyle = 'dotted', marker = 'o')
plt.legend(['Train', 'Test'])
plt.title('Desempeño')
plt.xlabel('Alpha')
plt.ylabel('Score')
#plt.xlim(-0.1, 0.3)
plt.ylim(0.5, 1.2)
plt.show()

'''
Como podemos observar, el valor de alpha cuando se encuentra entre 0.0 y 0.015 
tanto para test y train, da como resultado mejores scores, por ello se elegirá
el alpha que se encuentre en ese rango para tener predicciones más acertadas. 
'''

finalTree = DecisionTreeClassifier(criterion = 'entropy', 
                                   random_state = 0,
                                   max_depth = 6, 
                                   ccp_alpha = 0.00910266)
finalTree.fit(x_train, y_train)
print('=' * 10, 'Árbol Final', '=' * 10)
print('Score: ', finalTree.score(x_train, y_train))

"""### Visualización del Árbol de Decisión"""

print(tree.export_text(finalTree))

myTreeData = tree.export_graphviz(finalTree)
graphData = graphviz.Source(myTreeData)
graphData

feature_names = x.columns
class_names = ['Maligno', 'Benigno']
finalTreeData = tree.export_graphviz(finalTree, 
                                     feature_names = feature_names,
                                     class_names = class_names, 
                                     leaves_parallel = True,
                                     filled = True, 
                                     proportion = True, 
                                     rotate = False)
graphData = graphviz. Source(finalTreeData)
graphData

"""### Predicciones Usando el Mejor Modelo"""

# Prediccion de los valores usando el árbol de decisión 
prediccion = finalTree.predict(x_test)
# Valores reales de y
y_test = np.array(y_test)
print('=' * 80)
print('Valores De Entrada: ')
print(x_test)
print('=' * 80)
print('Valores Reales: ')
print(y_test)
print('=' * 80)
print('Predicción: ')
print(prediccion)

def statusPrediction(row):
  row.to_frame()
  real = row['real values']
  pred = row['prediction']
  if real == pred:
    return "Acertado"
  else:
    return "No Acertado"

df_x_test = pd.DataFrame(x_test)
column_name = list(df.columns)[:-1]
df_x_test.columns = column_name
df_x_test['real values'] = y_test
df_x_test['prediction'] = prediccion
df_x_test['status'] = df_x_test.apply(lambda row: statusPrediction(row), axis=1)
df_x_test

# Probabilidad 
print(finalTree.predict_proba(x_test))

"""### Métricas"""

# Classification Report
print(metrics.classification_report(y_test, prediccion, 
                                    target_names = ['Maligno', 'Benigno']))

print('Accuracy Score Test: ', metrics.accuracy_score(y_test, prediccion))
print('Precision Score Test: ', metrics.precision_score(y_test, prediccion))
print('Recall Score Test: ', metrics.recall_score(y_test, prediccion))

print('Matriz de Confusión: ')
confusion_matrix = metrics.confusion_matrix(y_test, prediccion, labels = [0, 1])
print(confusion_matrix)

ax = sns.heatmap(confusion_matrix, annot=True, cmap='Blues')
ax.set_title('Matriz de Confusión\n\n');
ax.set_xlabel('\nPredicted Values')
ax.set_ylabel('Actual Values ');
## Ticket labels - List must be in alphabetical order
ax.xaxis.set_ticklabels(['False','True'])
ax.yaxis.set_ticklabels(['False','True'])

## Display the visualization of the Confusion Matrix.
plt.show()

feature_importance = pd.DataFrame({'feature_names': feature_names, 'feature_importance': finalTree.feature_importances_})
feature_importance.sort_values(inplace = True, by = 'feature_importance', ascending = False)
feature_importance

feature_importance.plot.bar().set(title = 'Feature Importance')

plot_learning_curves(x_train, y_train, x_test, y_test, finalTree)
plt.ylim(-0.2, 0.2)
plt.show()

plot_learning_curves(x_train, y_train, x_test, y_test, decisionTree1)
plt.ylim(-0.2, 0.2)
plt.show()

'''
Cómo se puede observar en los gráficos anteriores, con el modelo finalTree se 
llegó a el fit deseado gracias a los valores que fueron elegidos para cada 
uno de los parámetros del árbol de decisión. 
'''

